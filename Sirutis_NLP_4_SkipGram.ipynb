{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Pytorch SkipGram"
      ],
      "metadata": {
        "id": "k-wyh8jLr3Fr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchdata"
      ],
      "metadata": {
        "id": "NkkQHfvhyWOc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "040356fe-681e-41e3-c304-76c49e877495"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchdata in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata) (1.26.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.27.1)\n",
            "Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.0.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchdata) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchdata) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchdata) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchdata) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchdata) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchdata) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->torchdata) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->torchdata) (16.0.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0->torchdata) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0->torchdata) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U torchtext"
      ],
      "metadata": {
        "id": "j_Nk6LNXs3Ju",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc46ab33-aeee-424b-9977-216ef11a5290"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (0.15.1)\n",
            "Collecting torchtext\n",
            "  Downloading torchtext-0.15.2-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.27.1)\n",
            "Collecting torch==2.0.1 (from torchtext)\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.22.4)\n",
            "Collecting torchdata==0.6.1 (from torchtext)\n",
            "  Downloading torchdata-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (3.1.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1->torchtext)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1->torchtext)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1->torchtext)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1->torchtext)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1->torchtext)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1->torchtext)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1->torchtext)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1->torchtext)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1->torchtext)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1->torchtext)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1->torchtext)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (2.0.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.6.1->torchtext) (1.26.15)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchtext) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchtext) (0.40.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchtext) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchtext) (16.0.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchtext) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchtext) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch, torchdata, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.0+cu118\n",
            "    Uninstalling torch-2.0.0+cu118:\n",
            "      Successfully uninstalled torch-2.0.0+cu118\n",
            "  Attempting uninstall: torchdata\n",
            "    Found existing installation: torchdata 0.6.0\n",
            "    Uninstalling torchdata-0.6.0:\n",
            "      Successfully uninstalled torchdata-0.6.0\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.15.1\n",
            "    Uninstalling torchtext-0.15.1:\n",
            "      Successfully uninstalled torchtext-0.15.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.0.1+cu118 requires torch==2.0.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.15.1+cu118 requires torch==2.0.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1 torchdata-0.6.1 torchtext-0.15.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install portalocker"
      ],
      "metadata": {
        "id": "fDOMfsoYtFb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29da96da-71c4-4572-a754-0e0d0da8d729"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Installing collected packages: portalocker\n",
            "Successfully installed portalocker-2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from functools import partial\n",
        "from torch.utils.data import DataLoader\n",
        "from torchtext.data import to_map_style_dataset\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.datasets import WikiText2, WikiText103\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from torchtext.vocab import vocab"
      ],
      "metadata": {
        "id": "Rrp9_jBqWB6T"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WINDOW_SIZE = 5\n",
        "BATCH_SIZE = 256    #\"<YOUR CODE>\"\n",
        "EMB_DIM = 256         #\"<YOUR CODE>\"\n",
        "EPOCHS = 15          #\"<YOUR CODE>\""
      ],
      "metadata": {
        "id": "HwL5oNuouJpd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    #\"<YOUR CODE>\"\n",
        "  device = torch.device('cuda') # Если мы используем GPU\n",
        "else:\n",
        "  #\"<YOUR CODE>\"\n",
        "  device = torch.device('cpu') # Если мы используем CPU"
      ],
      "metadata": {
        "id": "lP0TtK6pu7ay"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://s3.amazonaws.com/fast-ai-nlp/wikitext-2.tgz -O wikitext-2.tar.gz\n",
        "!tar -xvzf wikitext-2.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZVsPPD6wOL7",
        "outputId": "1ea1fc25-65ca-4b99-f003-2f0d0843f6fe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-11 16:14:23--  https://s3.amazonaws.com/fast-ai-nlp/wikitext-2.tgz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.233.232, 52.216.248.86, 52.217.203.64, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.233.232|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4070055 (3.9M) [application/x-tar]\n",
            "Saving to: ‘wikitext-2.tar.gz’\n",
            "\n",
            "wikitext-2.tar.gz   100%[===================>]   3.88M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-05-11 16:14:24 (27.1 MB/s) - ‘wikitext-2.tar.gz’ saved [4070055/4070055]\n",
            "\n",
            "wikitext-2/\n",
            "wikitext-2/train.csv\n",
            "wikitext-2/test.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(filepath):\n",
        "  with open(filepath) as f:\n",
        "    return f.readlines()"
      ],
      "metadata": {
        "id": "CldDKoACxXTs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = load_data(\"wikitext-2/train.csv\")\n",
        "test = load_data(\"wikitext-2/test.csv\")\n",
        "data = train + test"
      ],
      "metadata": {
        "id": "S_TpDY1_xkev"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = get_tokenizer(\"basic_english\", language=\"en\")"
      ],
      "metadata": {
        "id": "GSP92oeztJIc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def yield_tokens(data_obj):\n",
        "  for text in data_obj:\n",
        "    yield tokenizer(text)\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens(data), specials=[\"<unk>\"], min_freq=20)\n",
        "vocab.set_default_index(vocab[\"<unk>\"])"
      ],
      "metadata": {
        "id": "3vQXOLDitSoI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsUugBUByDH3",
        "outputId": "7ba9208f-c6bc-44a6-c5f0-747391c8ab00"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8627"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab['asdasdasd']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RByqqqdzgdE",
        "outputId": "f6b7d07f-b05a-459f-f64a-4a99360d96af"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_pipeline = lambda x: vocab(tokenizer(x))"
      ],
      "metadata": {
        "id": "EaN1Nhgftx5H"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_contexts(row, window_size=3):\n",
        "  contexts = []\n",
        "  for i in range(len(row)):\n",
        "    central_word = row[i]\n",
        "    context = [row[i + delta] for delta in range(-window_size, window_size + 1) if delta != 0 and i + delta >= 0 and i + delta < len(row)]\n",
        "\n",
        "    for c_w in context:\n",
        "      contexts.append((central_word, c_w)) \n",
        "    return contexts"
      ],
      "metadata": {
        "id": "PZfDc-7Pu015"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Word2VecDataset(Dataset):\n",
        "  def __init__(self, data, vocab, wsize=3):\n",
        "    self.vocab_size = len(vocab)\n",
        "    self.data = [text_pipeline(item) for item in data]\n",
        "    self.data = [item for text in self.data for item in text]\n",
        "    self.data = build_contexts(self.data, window_size=wsize)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.data[idx]"
      ],
      "metadata": {
        "id": "NVNMh-btt9RV"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Word2VecDataset(data, vocab)\n",
        "train_dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle= True)\n",
        "#\"<YOUR CODE>\""
      ],
      "metadata": {
        "id": "c0IFzWJKtv4k"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "central_word, context = dataset[0]\n",
        "central_word, context "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ubic5ki32bof",
        "outputId": "09cb1275-eeb8-4c9e-f427-44dd49011e1c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 435)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SkipGram_Model(nn.Module):\n",
        "  def __init__(self, vocab_size: int):\n",
        "    super(SkipGram_Model, self).__init__()\n",
        "    self.embeddings = nn.Embedding(\n",
        "        num_embeddings= vocab_size,\n",
        "        embedding_dim= EMB_DIM\n",
        "       #\"<YOUR CODE>\"\n",
        "    )\n",
        "    self.linear = nn.Linear(\n",
        "        in_features= EMB_DIM,\n",
        "        out_features= vocab_size\n",
        "        #\"<YOUR CODE>\"\n",
        "    )\n",
        "\n",
        "  def forward(self, inputs_):\n",
        "    x = self.embeddings(inputs_)\n",
        "    x = self.linear(x)\n",
        "    #\"<YOUR CODE>\"\n",
        "    return x"
      ],
      "metadata": {
        "id": "BkN3VOShvsoW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab)\n",
        "#\"<YOUR CODE>\"\n",
        "model = SkipGram_Model(vocab_size)\n",
        "if torch.cuda.is_available():\n",
        "  model = model.cuda()"
      ],
      "metadata": {
        "id": "feiqkWxgw91Q"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IpF3fGXo9EcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()   #\"<YOUR CODE>\"\n",
        "optimizer = torch.optim.Adam(model.parameters())   #\"<YOUR CODE>\"\n",
        "#optimizer = torch.optim.SGD(model.parameters()) \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "n_s6nEdTw8as"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train_model(dataloader, model, optimizer, criterion):\n",
        "  epoch_loss=[]\n",
        "        \n",
        "  for word, context in tqdm(train_dataloader):\n",
        "    optimizer.zero_grad() \n",
        "    pred = model(word.to(device))\n",
        "    loss = criterion (pred, context.to(device))  \n",
        "    loss.backward()      \n",
        "    epoch_loss.append(loss.detach().cpu().numpy())\n",
        "    optimizer.step()\n",
        "       \n",
        "    #\"<YOUR CODE>\"\n",
        "  return np.mean(epoch_loss) "
      ],
      "metadata": {
        "id": "ZMFwTTE1uV_n"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  loss = train_model(train_dataloader, model, optimizer, criterion)\n",
        "  if epoch % 2 == 0:\n",
        "    print(f'Epoch {epoch}: train loss {loss}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7poLNsQuass",
        "outputId": "aca0f16e-e5ff-4311-8ba6-74a93a2330b2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  4.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: train loss 9.017966270446777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  8.74it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  7.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: train loss 8.182194709777832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 13.27it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  8.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: train loss 7.346827983856201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 12.04it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  7.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: train loss 6.51238489151001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 14.18it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 16.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: train loss 5.68066930770874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 15.64it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 17.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: train loss 4.856422424316406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 14.96it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 18.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12: train loss 4.050792694091797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 15.76it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 15.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14: train loss 3.2874410152435303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = list(model.parameters())[0]\n",
        "embeddings = embeddings.cpu().detach().numpy()\n",
        "\n",
        "# normalization\n",
        "norms = (embeddings ** 2).sum(axis=1) ** (1 / 2)\n",
        "norms = np.reshape(norms, (len(norms), 1))\n",
        "embeddings_norm = embeddings / norms\n",
        "embeddings_norm.shape"
      ],
      "metadata": {
        "id": "sBycwJCD0k2x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4215f772-362b-4fbb-ef4a-88fa3a49e9d8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8627, 256)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_similar(word, n=10):\n",
        "    word_id = vocab[word]\n",
        "    if word_id == 0:\n",
        "        print(\"Out of vocabulary word\")\n",
        "        return\n",
        "\n",
        "    word_vec = embeddings_norm[word_id]\n",
        "    word_vec = np.reshape(word_vec, (len(word_vec), 1))\n",
        "    dists = np.matmul(embeddings_norm, word_vec).flatten()\n",
        "    top_ids = np.argsort(-dists)[1 : n + 1]\n",
        "\n",
        "    top_dict = {}\n",
        "    for sim_word_id in top_ids:\n",
        "        sim_word = vocab.lookup_token(sim_word_id)\n",
        "        top_dict[sim_word] = dists[sim_word_id]\n",
        "    return top_dict"
      ],
      "metadata": {
        "id": "i_eVIj720qtq"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_top_similar('hero')"
      ],
      "metadata": {
        "id": "xInWGLGA0qpf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e40602c8-72fa-41c6-80a9-a553e43babf1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'makes': 0.24810466,\n",
              " 'aged': 0.22608688,\n",
              " 'popular': 0.21625467,\n",
              " 'enclosed': 0.19651905,\n",
              " 'astronomical': 0.19627309,\n",
              " 'grain': 0.19179407,\n",
              " 'efficient': 0.1910615,\n",
              " '275': 0.19070694,\n",
              " 'indu': 0.19019961,\n",
              " 'layers': 0.18766634}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}